{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPtl+TtCLoeqsxbj07il6+X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kh-ops69/ML_NLP/blob/master/extractive_summarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text Summarization: Getting a summary of text from given sample document. We use different methods, using both pre-built libraries and a custom function to obtain these summaries. difference of outputs between different methods arises due to the fact that all of them use some variation of the same basic idea to obtain summary."
      ],
      "metadata": {
        "id": "brugEYpi6juv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "H1fFoTfWLp02"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
        "import textwrap\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import tokenize\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sumy.summarizers.text_rank import TextRankSummarizer\n",
        "from sumy.summarizers.lsa import LsaSummarizer\n",
        "from sumy.parsers.plaintext import PlaintextParser\n",
        "from sumy.nlp.tokenizers import Tokenizer"
      ],
      "metadata": {
        "id": "5e3drQQ03_bX"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PIHwAOYOHNh",
        "outputId": "71402347-6aba-45d8-eb8e-90093e198bd7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -nc https://lazyprogrammer.me/course_files/nlp/bbc_text_cls.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyYcXEHoORSx",
        "outputId": "87de092c-0a52-45bd-f71a-0ace672a77b9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File ‘bbc_text_cls.csv’ already there; not retrieving.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"bbc_text_cls.csv\")"
      ],
      "metadata": {
        "id": "2yA4npEcjbLF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.sample(5), df.labels.unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkPkZfxKji0b",
        "outputId": "272fe6ff-0723-4a1a-887b-7cc53a9068ae"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(                                                   text         labels\n",
              " 525   Arthur Hailey: King of the bestsellers\\n\\nNove...  entertainment\n",
              " 1987  Who do you think you are?\\n\\nThe real danger i...           tech\n",
              " 627   REM concerts blighted by illness\\n\\nUS rock ba...  entertainment\n",
              " 371   Madagascar completes currency switch\\n\\nMadaga...       business\n",
              " 1683  All Black magic: New Zealand rugby\\n\\nPlaying ...          sport,\n",
              " array(['business', 'entertainment', 'politics', 'sport', 'tech'],\n",
              "       dtype=object))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def wrap(x):\n",
        "  return textwrap.fill(x, replace_whitespace=False, fix_sentence_endings = True)"
      ],
      "metadata": {
        "id": "3sTFTiO_jsTw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.iloc[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMpxPYTZkEOP",
        "outputId": "917ec9b4-217a-4cc7-d377-c96a453b74e0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text      Ad sales boost Time Warner profit\\n\\nQuarterly...\n",
              "labels                                             business\n",
              "Name: 0, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(wrap(df.iloc[1].text.split(\"\\n\", 1)[1]))\n",
        "\n",
        "# split once (arg=1), split by char(\\n), and retrieve the second element after\n",
        "# splitting, in this case, (title, text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vM31VPVKj-ZX",
        "outputId": "ccb7871c-3ad8-41bf-b251-b7706399e133"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The dollar has hit its highest level against the euro in almost three\n",
            "months after the Federal Reserve head said the US trade deficit is set\n",
            "to stabilise.\n",
            "\n",
            "And Alan Greenspan highlighted the US government's\n",
            "willingness to curb spending and rising household savings as factors\n",
            "which may help to reduce it.  In late trading in New York, the dollar\n",
            "reached $1.2871 against the euro, from $1.2974 on Thursday.  Market\n",
            "concerns about the deficit has hit the greenback in recent months.  On\n",
            "Friday, Federal Reserve chairman Mr Greenspan's speech in London ahead\n",
            "of the meeting of G7 finance ministers sent the dollar higher after it\n",
            "had earlier tumbled on the back of worse-than-expected US jobs data.\n",
            "\"I think the chairman's taking a much more sanguine view on the\n",
            "current account deficit than he's taken for some time,\" said Robert\n",
            "Sinche, head of currency strategy at Bank of America in New York.\n",
            "\"He's taking a longer-term view, laying out a set of conditions under\n",
            "which the current account deficit can improve this year and next.\"\n",
            "Worries about the deficit concerns about China do, however, remain.\n",
            "China's currency remains pegged to the dollar and the US currency's\n",
            "sharp falls in recent months have therefore made Chinese export prices\n",
            "highly competitive.  But calls for a shift in Beijing's policy have\n",
            "fallen on deaf ears, despite recent comments in a major Chinese\n",
            "newspaper that the \"time is ripe\" for a loosening of the peg.  The G7\n",
            "meeting is thought unlikely to produce any meaningful movement in\n",
            "Chinese policy.  In the meantime, the US Federal Reserve's decision on\n",
            "2 February to boost interest rates by a quarter of a point - the sixth\n",
            "such move in as many months - has opened up a differential with\n",
            "European rates.  The half-point window, some believe, could be enough\n",
            "to keep US assets looking more attractive, and could help prop up the\n",
            "dollar.  The recent falls have partly been the result of big budget\n",
            "deficits, as well as the US's yawning current account gap, both of\n",
            "which need to be funded by the buying of US bonds and assets by\n",
            "foreign firms and governments.  The White House will announce its\n",
            "budget on Monday, and many commentators believe the deficit will\n",
            "remain at close to half a trillion dollars.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tf_summarizer(texts, arg, factor):\n",
        "  sents = texts.split(\"\\n\", 1)[1]\n",
        "  sents = nltk.sent_tokenize(sents)\n",
        "  # tokens = nltk.sent_tokenize(sents)\n",
        "  featurizer = TfidfVectorizer(max_features=1500, stop_words=stopwords.words(\"english\"), norm='l1')\n",
        "  x = featurizer.fit_transform(sents)\n",
        "  if arg==\"s\":\n",
        "    s = cosine_similarity(x)\n",
        "    s /= s.sum(axis=1, keepdims=True)\n",
        "    u = np.ones_like(s)/len(s)\n",
        "    # creating a new matrix in order to aid with the smoothing process\n",
        "    s = (1-factor)*s + factor*u\n",
        "    # factor component arises in order to control how much weightage is given to each component s and u\n",
        "    eigenvals, eigenvecs = np.linalg.eig(s.T)\n",
        "\n",
        "    # for more in-depth understanding, some low level code\n",
        "\n",
        "    # limiting_dist = np.ones(len(s))/ len(s)\n",
        "    # threshold = 1e-10\n",
        "    # delta = float('-inf')\n",
        "    # iters = 0\n",
        "    # while delta>threshold:\n",
        "    #   iters += 1\n",
        "    #   # getting the new state transition matrix\n",
        "    #   p = limiting_dist.dot(s)\n",
        "    #   # updating the difference between limiting distribution and state transition matrix:\n",
        "    #   # it will help us in iteratively updating delta as and when the\n",
        "    #   # limiting distribuion comes closer and closer to stationary distribution\n",
        "    #   delta = np.abs(p-limiting_dist).sum()\n",
        "    #   limiting_dist = p\n",
        "    # print(iters, limiting_dist.sum(), np.abs(eigenvecs[:,0] / eigenvecs[:,0].sum() - limiting_dist).sum())\n",
        "\n",
        "    scores = eigenvecs[:,0] / eigenvecs[:,0].sum()\n",
        "    sort_idxes = (-scores).argsort()\n",
        "    for i in sort_idxes[:5]:\n",
        "      print(wrap(\"%.2f: %s\"% (scores[i], sents[i])))\n",
        "\n",
        "  # same procedure: replacing cosine similarity for euclidean distances\n",
        "  elif arg==\"e\":\n",
        "    e = euclidean_distances(x)\n",
        "    e /= e.sum(axis=1, keepdims=True)\n",
        "    u = np.ones_like(e)/len(e)\n",
        "    e = (1-factor)*e + factor*u\n",
        "    eigenvals, eigenvecs = np.linalg.eig(e.T)\n",
        "    scores = eigenvecs[:,0] / eigenvecs[:,0].sum()\n",
        "    sort_idxes = (-scores).argsort()\n",
        "    for i in sort_idxes[:5]:\n",
        "      print(wrap(\"%.2f: %s\"% (scores[i], sents[i])))"
      ],
      "metadata": {
        "id": "xt2jgFJEk0t1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.iloc[1].text.split(\"\\n\", 1)[0], df.iloc[1].labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJ00CvpFxV-l",
        "outputId": "1d8a06bf-4939-462c-fe9f-fd9783632346"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Dollar gains on Greenspan speech', 'business')"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we will check using cosine similarity"
      ],
      "metadata": {
        "id": "G5wcskBz07IY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf_summarizer(df.iloc[1].text, \"s\", factor=0.3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dotEoKMLuyXC",
        "outputId": "bd160de0-e4e1-45cf-9648-f0b7c695e171"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.08: \n",
            "The dollar has hit its highest level against the euro in almost\n",
            "three months after the Federal Reserve head said the US trade deficit\n",
            "is set to stabilise.\n",
            "0.07: \"I think the chairman's taking a much more sanguine view on the\n",
            "current account deficit than he's taken for some time,\" said Robert\n",
            "Sinche, head of currency strategy at Bank of America in New York.\n",
            "0.07: China's currency remains pegged to the dollar and the US\n",
            "currency's sharp falls in recent months have therefore made Chinese\n",
            "export prices highly competitive.\n",
            "0.07: Market concerns about the deficit has hit the greenback in\n",
            "recent months.\n",
            "0.07: On Friday, Federal Reserve chairman Mr Greenspan's speech in\n",
            "London ahead of the meeting of G7 finance ministers sent the dollar\n",
            "higher after it had earlier tumbled on the back of worse-than-expected\n",
            "US jobs data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Second method is euclidean distances"
      ],
      "metadata": {
        "id": "SCDY5mdz0_VH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf_summarizer(df.iloc[1].text, \"e\", factor=0.3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pqGkmp0zspG",
        "outputId": "2ca62a47-5bde-4e24-b6ca-f57edc2ba4df"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.08: Worries about the deficit concerns about China do, however,\n",
            "remain.\n",
            "0.08: Market concerns about the deficit has hit the greenback in\n",
            "recent months.\n",
            "0.07: The G7 meeting is thought unlikely to produce any meaningful\n",
            "movement in Chinese policy.\n",
            "0.07: In late trading in New York, the dollar reached $1.2871 against\n",
            "the euro, from $1.2974 on Thursday.\n",
            "0.07: The half-point window, some believe, could be enough to keep US\n",
            "assets looking more attractive, and could help prop up the dollar.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using some pre-built libraries to obtain summaries instead"
      ],
      "metadata": {
        "id": "ycAT26Z71DTS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summarizer = TextRankSummarizer()\n",
        "parser = PlaintextParser(df.iloc[1].text.split('\\n',1)[1], Tokenizer('english'))\n",
        "summary = summarizer(parser.document, sentences_count=5)"
      ],
      "metadata": {
        "id": "UJsSTqiJ4dwl"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_wrap(summary):\n",
        "  for sentence in summary:\n",
        "    print(wrap(str(sentence)))"
      ],
      "metadata": {
        "id": "bOHDDlYv5A5b"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_wrap(summary=summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GU9HVu2_5uV7",
        "outputId": "b3fac8d9-a74f-44ef-b14c-5142d77edc81"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dollar has hit its highest level against the euro in almost three\n",
            "months after the Federal Reserve head said the US trade deficit is set\n",
            "to stabilise.\n",
            "On Friday, Federal Reserve chairman Mr Greenspan's speech in London\n",
            "ahead of the meeting of G7 finance ministers sent the dollar higher\n",
            "after it had earlier tumbled on the back of worse-than-expected US\n",
            "jobs data.\n",
            "But calls for a shift in Beijing's policy have fallen on deaf ears,\n",
            "despite recent comments in a major Chinese newspaper that the \"time is\n",
            "ripe\" for a loosening of the peg.\n",
            "In the meantime, the US Federal Reserve's decision on 2 February to\n",
            "boost interest rates by a quarter of a point - the sixth such move in\n",
            "as many months - has opened up a differential with European rates.\n",
            "The recent falls have partly been the result of big budget deficits,\n",
            "as well as the US's yawning current account gap, both of which need to\n",
            "be funded by the buying of US bonds and assets by foreign firms and\n",
            "governments.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Lsumm = LsaSummarizer()\n",
        "second_summ = Lsumm(parser.document, sentences_count=5)\n",
        "get_wrap(second_summ)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGGAwWjV5VWj",
        "outputId": "bebd204b-6798-4d59-b0ef-fe24e00be80f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "And Alan Greenspan highlighted the US government's willingness to curb\n",
            "spending and rising household savings as factors which may help to\n",
            "reduce it.\n",
            "\"I think the chairman's taking a much more sanguine view on the\n",
            "current account deficit than he's taken for some time,\" said Robert\n",
            "Sinche, head of currency strategy at Bank of America in New York.\n",
            "China's currency remains pegged to the dollar and the US currency's\n",
            "sharp falls in recent months have therefore made Chinese export prices\n",
            "highly competitive.\n",
            "The G7 meeting is thought unlikely to produce any meaningful movement\n",
            "in Chinese policy.\n",
            "The White House will announce its budget on Monday, and many\n",
            "commentators believe the deficit will remain at close to half a\n",
            "trillion dollars.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gzy4owko25ts",
        "outputId": "8c324d62-0dc8-4b45-c3e6-b753292bb906"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wheel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVfA83qq193e",
        "outputId": "14bc627b-2f46-4521-f063-43b40fcdcfe0"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (0.40.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim==3.6.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "LYBvy8e-1n54",
        "outputId": "aaf971d4-71e9-44ab-b325-b3fe624e1d44"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim==3.6.0\n",
            "  Downloading gensim-3.6.0.tar.gz (23.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.1/23.1 MB\u001b[0m \u001b[31m67.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.10/dist-packages (from gensim==3.6.0) (1.22.4)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.10/dist-packages (from gensim==3.6.0) (1.10.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from gensim==3.6.0) (1.16.0)\n",
            "Requirement already satisfied: smart_open>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from gensim==3.6.0) (6.3.0)\n",
            "Building wheels for collected packages: gensim\n",
            "  Building wheel for gensim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gensim: filename=gensim-3.6.0-cp310-cp310-linux_x86_64.whl size=23916462 sha256=c116cb4e81635aecd7decf0deea4dab114f7c0b73833d85b42324d36b743702e\n",
            "  Stored in directory: /root/.cache/pip/wheels/00/e8/47/96f55c3144a5ea3537f549f7a97607011f5004b9f13fa8dcc5\n",
            "Successfully built gensim\n",
            "Installing collected packages: gensim\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 4.3.1\n",
            "    Uninstalling gensim-4.3.1:\n",
            "      Successfully uninstalled gensim-4.3.1\n",
            "Successfully installed gensim-3.6.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gensim"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sumy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08ECQCWg4Jln",
        "outputId": "9896dd2c-3d39-4f51-a56e-4f81eee40e74"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sumy\n",
            "  Downloading sumy-0.11.0-py2.py3-none-any.whl (97 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/97.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.3/97.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docopt<0.7,>=0.6.1 (from sumy)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting breadability>=0.1.20 (from sumy)\n",
            "  Downloading breadability-0.1.20.tar.gz (32 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from sumy) (2.27.1)\n",
            "Collecting pycountry>=18.2.23 (from sumy)\n",
            "  Downloading pycountry-22.3.5.tar.gz (10.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: nltk>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from sumy) (3.8.1)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from breadability>=0.1.20->sumy) (4.0.0)\n",
            "Requirement already satisfied: lxml>=2.0 in /usr/local/lib/python3.10/dist-packages (from breadability>=0.1.20->sumy) (4.9.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (4.65.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from pycountry>=18.2.23->sumy) (67.7.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (3.4)\n",
            "Building wheels for collected packages: breadability, docopt, pycountry\n",
            "  Building wheel for breadability (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for breadability: filename=breadability-0.1.20-py2.py3-none-any.whl size=21696 sha256=83ffe06f39f3c6a6e581a8af4cedf02e046d1ee7be887881dc3238ce2b81f721\n",
            "  Stored in directory: /root/.cache/pip/wheels/64/22/90/b84fcc30e16598db20a0d41340616dbf9b1e82bbcc627b0b33\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13707 sha256=951bb063be819a55fe2e7fc0a4810cf457fa72df4d2d36b0c7266a04f780064a\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "  Building wheel for pycountry (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycountry: filename=pycountry-22.3.5-py2.py3-none-any.whl size=10681832 sha256=a592c89bc0970fd6c19eb52f4a3c2744b3c57bc694c5e00ad90dfc1af2a8657d\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/57/cc/290c5252ec97a6d78d36479a3c5e5ecc76318afcb241ad9dbe\n",
            "Successfully built breadability docopt pycountry\n",
            "Installing collected packages: docopt, pycountry, breadability, sumy\n",
            "Successfully installed breadability-0.1.20 docopt-0.6.2 pycountry-22.3.5 sumy-0.11.0\n"
          ]
        }
      ]
    }
  ]
}